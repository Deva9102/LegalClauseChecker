{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"1K35dvppZG5EEPZoUcQN6cKaXGhbR0vFZ","authorship_tag":"ABX9TyN8Ba2P7DqJXquSWv9J+h0J"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"aa337951aa3b427aa14038a0359859fe":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e6685670a08143578e3ba062abd2509a","IPY_MODEL_40e29f8556194ce4a86ea286f2a5f40b","IPY_MODEL_9cf6f0ecf2094425b487af5f7d0cf462"],"layout":"IPY_MODEL_a7175696d4f9484f83a3fe74c1faa716"}},"e6685670a08143578e3ba062abd2509a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5c8edbdac53e4208a2b812f0b969033e","placeholder":"​","style":"IPY_MODEL_0d52f831894c4bf3a598647736d1ca29","value":"tokenizer_config.json: 100%"}},"40e29f8556194ce4a86ea286f2a5f40b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6c6cef52fe724612b521f5d13a2c0fc4","max":48,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f079b8cb27f04541bec84ed39b387b7a","value":48}},"9cf6f0ecf2094425b487af5f7d0cf462":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bceb467678a947479005528c9f5a9122","placeholder":"​","style":"IPY_MODEL_3cb55c545f3146569abce03700f08096","value":" 48.0/48.0 [00:00&lt;00:00, 1.94kB/s]"}},"a7175696d4f9484f83a3fe74c1faa716":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5c8edbdac53e4208a2b812f0b969033e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0d52f831894c4bf3a598647736d1ca29":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6c6cef52fe724612b521f5d13a2c0fc4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f079b8cb27f04541bec84ed39b387b7a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"bceb467678a947479005528c9f5a9122":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3cb55c545f3146569abce03700f08096":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5626ec1a27e843f6b9c2ead882fde64b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_bffe7d90a4464ade9508878a36e926bd","IPY_MODEL_277d0b9d28a0445b98f2e6cdb6ef6892","IPY_MODEL_579efaecdf3e42e79163a3a91895fd48"],"layout":"IPY_MODEL_3692b41f934c4229b0c0c5532b30ee24"}},"bffe7d90a4464ade9508878a36e926bd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_25727ead43034fb7a8159129ee80d35e","placeholder":"​","style":"IPY_MODEL_4698876b0de144dbbf2e0a78f614cebf","value":"config.json: 100%"}},"277d0b9d28a0445b98f2e6cdb6ef6892":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a4b8244af6b1423e8304de6b2eca4084","max":570,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d499e8c92a9646f5900c87161f285411","value":570}},"579efaecdf3e42e79163a3a91895fd48":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f2062bf200444ead9f3d7f7555f47aa3","placeholder":"​","style":"IPY_MODEL_cc9e786219d3498a9fab01e71231fda5","value":" 570/570 [00:00&lt;00:00, 18.2kB/s]"}},"3692b41f934c4229b0c0c5532b30ee24":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"25727ead43034fb7a8159129ee80d35e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4698876b0de144dbbf2e0a78f614cebf":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a4b8244af6b1423e8304de6b2eca4084":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d499e8c92a9646f5900c87161f285411":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f2062bf200444ead9f3d7f7555f47aa3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cc9e786219d3498a9fab01e71231fda5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6b8d851ac8b1418da211fe09357be446":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_397c43b52c074f4dafcfcf6810b24e58","IPY_MODEL_14360db516d1493a95f55e5fb85a8ca0","IPY_MODEL_2c0f0b618c8744f589de07167bd3780b"],"layout":"IPY_MODEL_07a17416889f4ef2bd65787dd9cc6eb9"}},"397c43b52c074f4dafcfcf6810b24e58":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e86bececf8ca4bfbb4e30cf408e3c3ae","placeholder":"​","style":"IPY_MODEL_c2677e76b394444493640a1b1e030537","value":"vocab.txt: 100%"}},"14360db516d1493a95f55e5fb85a8ca0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_dc2fcc3147fe4db6bc4d8ee43307bbf0","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_65e6ca3d277747e69a612fa321747576","value":231508}},"2c0f0b618c8744f589de07167bd3780b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2aae028167484810bb56936b50b81634","placeholder":"​","style":"IPY_MODEL_b2c0884b8c0b457ba36d887217b6219f","value":" 232k/232k [00:00&lt;00:00, 1.40MB/s]"}},"07a17416889f4ef2bd65787dd9cc6eb9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e86bececf8ca4bfbb4e30cf408e3c3ae":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c2677e76b394444493640a1b1e030537":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"dc2fcc3147fe4db6bc4d8ee43307bbf0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"65e6ca3d277747e69a612fa321747576":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2aae028167484810bb56936b50b81634":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b2c0884b8c0b457ba36d887217b6219f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"871ec9948de244689dce5f64af54e42c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c43970ce24a649ea9ff7c01c0831552d","IPY_MODEL_74b9226d9cce49639b1a9a83a3e112a0","IPY_MODEL_b804b29717b543299b6176ea12a32bfb"],"layout":"IPY_MODEL_5208691ac1dc460299c29b6492e03f36"}},"c43970ce24a649ea9ff7c01c0831552d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e934d7fa6a9a4d55ba7b3a36d054a8b7","placeholder":"​","style":"IPY_MODEL_98275ace4f7643e29bebbb6d728312f8","value":"tokenizer.json: 100%"}},"74b9226d9cce49639b1a9a83a3e112a0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1f259ee66f8943b8a70379f3ffbd5ded","max":466062,"min":0,"orientation":"horizontal","style":"IPY_MODEL_17b3d52cccbf4ff7b700c2203a48de3a","value":466062}},"b804b29717b543299b6176ea12a32bfb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_76699ff51e074a91b368a0c6ff47738b","placeholder":"​","style":"IPY_MODEL_a413f1d99746417290eb25a4ff75281f","value":" 466k/466k [00:00&lt;00:00, 2.89MB/s]"}},"5208691ac1dc460299c29b6492e03f36":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e934d7fa6a9a4d55ba7b3a36d054a8b7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"98275ace4f7643e29bebbb6d728312f8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1f259ee66f8943b8a70379f3ffbd5ded":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"17b3d52cccbf4ff7b700c2203a48de3a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"76699ff51e074a91b368a0c6ff47738b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a413f1d99746417290eb25a4ff75281f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fd0c649047034feb9e18f75e92183195":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ccb28b01548a460cbd1b66ce2c40fede","IPY_MODEL_5a205b3a48c846d2b7e602ad1a0afef7","IPY_MODEL_6bd87ed309c34ba8b6a37edd2e5a479e"],"layout":"IPY_MODEL_536a82a6a1a2425ea2cefe814fbaeb80"}},"ccb28b01548a460cbd1b66ce2c40fede":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9c9e0a938c9d461ba9573c1d6a6854a8","placeholder":"​","style":"IPY_MODEL_a607efe79ca141f4b1c15d375f6822ab","value":"model.safetensors: 100%"}},"5a205b3a48c846d2b7e602ad1a0afef7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_74d6e30654844e96bc646bbacacd2ad6","max":440449768,"min":0,"orientation":"horizontal","style":"IPY_MODEL_93215596f9824fcf8a9f82b4c85ea7f0","value":440449768}},"6bd87ed309c34ba8b6a37edd2e5a479e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ace1bedc57fe47ad95791afc313b52d6","placeholder":"​","style":"IPY_MODEL_b45bbe429cd44b1c9ba57144fa04540d","value":" 440M/440M [00:08&lt;00:00, 55.4MB/s]"}},"536a82a6a1a2425ea2cefe814fbaeb80":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9c9e0a938c9d461ba9573c1d6a6854a8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a607efe79ca141f4b1c15d375f6822ab":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"74d6e30654844e96bc646bbacacd2ad6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"93215596f9824fcf8a9f82b4c85ea7f0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ace1bedc57fe47ad95791afc313b52d6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b45bbe429cd44b1c9ba57144fa04540d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["### Load data"],"metadata":{"id":"kHMCNZSGS7H6"}},{"cell_type":"code","source":["import pandas as pd\n","import pickle\n","import numpy as np\n","\n","# Load saved files\n","df_labeled = pd.read_pickle(\"/content/drive/MyDrive/data_cuad_transformer/df_labeled.pkl\")\n","\n","with open(\"/content/drive/MyDrive/data_cuad_transformer/label_names.pkl\", \"rb\") as f:\n","    label_names = pickle.load(f)\n","\n","pos_weight = np.load(\"/content/drive/MyDrive/data_cuad_transformer/pos_weight.npy\")\n","\n","print(\"Loaded df_labeled, label_names, pos_weight\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9e128D3SS93E","executionInfo":{"status":"ok","timestamp":1755089486189,"user_tz":240,"elapsed":8987,"user":{"displayName":"3012 DEVADARSHINI P.T","userId":"12107410435582174408"}},"outputId":"87810f6d-27c3-40e4-d300-3e749ab6eff5"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Loaded df_labeled, label_names, pos_weight\n"]}]},{"cell_type":"markdown","source":["### BERT Tokenization"],"metadata":{"id":"acvvYvWHWHcr"}},{"cell_type":"code","source":["import os, json, numpy as np, pandas as pd, pickle, time\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader\n","from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoConfig\n","from torch.optim import AdamW\n","from sklearn.metrics import f1_score, precision_score, recall_score\n","from sklearn.model_selection import train_test_split\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(\"Using device:\", device)\n","\n","df_labeled = pd.read_pickle(\"/content/drive/MyDrive/data_cuad_transformer/df_labeled.pkl\")\n","with open(\"/content/drive/MyDrive/data_cuad_transformer/label_names.pkl\", \"rb\") as f:\n","    label_names = pickle.load(f)\n","\n","df_labeled[\"y_multi\"] = df_labeled[\"y_multi\"].apply(lambda v: np.asarray(v, dtype=np.float32))\n","y_lengths = df_labeled[\"y_multi\"].map(lambda v: v.shape[0]).unique()\n","if len(y_lengths) != 1:\n","    raise ValueError(f\"Inconsistent y_multi lengths across rows: {y_lengths}\")\n","TRUE_NUM_LABELS = int(y_lengths[0])\n","\n","if 'label_names' in globals():\n","    if len(label_names) != TRUE_NUM_LABELS:\n","        print(f\"[warn] label_names len={len(label_names)}\")\n","        if len(label_names) > TRUE_NUM_LABELS:\n","            label_names = list(label_names)[:TRUE_NUM_LABELS]\n","        else:\n","            label_names = list(label_names) + [f\"label_{i}\" for i in range(len(label_names), TRUE_NUM_LABELS)]\n","\n","NUM_LABELS = TRUE_NUM_LABELS\n","print(\"NUM_LABELS:\", NUM_LABELS)\n","\n","def align_matrix(mat, num_labels):\n","    mat = np.asarray(mat, dtype=np.float32)\n","    if mat.ndim == 1:\n","        mat = mat[None, :]\n","    if mat.shape[1] > num_labels:\n","        return mat[:, :num_labels]\n","    if mat.shape[1] < num_labels:\n","        pad = np.zeros((mat.shape[0], num_labels - mat.shape[1]), dtype=np.float32)\n","        return np.hstack([mat, pad])\n","    return mat"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9xD_6FR9PZCI","executionInfo":{"status":"ok","timestamp":1755089580197,"user_tz":240,"elapsed":149,"user":{"displayName":"3012 DEVADARSHINI P.T","userId":"12107410435582174408"}},"outputId":"e24e7314-4269-4169-99c1-711f89aebc7f"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Using device: cuda\n","[warn] label_names len=40\n","NUM_LABELS: 41\n"]}]},{"cell_type":"code","source":["class ClauseDataset(Dataset):\n","    def __init__(self, texts, labels, tokenizer, max_len=512, num_labels=None):\n","        self.texts = list(texts)\n","        arr = np.array(list(labels), dtype=np.float32)\n","        if num_labels is not None:\n","            arr = align_matrix(arr, num_labels)\n","        self.labels = arr\n","        self.tokenizer = tokenizer\n","        self.max_len = max_len\n","\n","    def __len__(self): return len(self.texts)\n","\n","    def __getitem__(self, idx):\n","        enc = self.tokenizer(\n","            self.texts[idx],\n","            truncation=True,\n","            padding=\"max_length\",\n","            max_length=self.max_len,\n","            return_tensors=\"pt\"\n","        )\n","        item = {k: v.squeeze(0) for k, v in enc.items()}\n","        item[\"labels\"] = torch.tensor(self.labels[idx], dtype=torch.float32)\n","        return item"],"metadata":{"id":"5wwGzvXgQ67E","executionInfo":{"status":"ok","timestamp":1755090536389,"user_tz":240,"elapsed":12,"user":{"displayName":"3012 DEVADARSHINI P.T","userId":"12107410435582174408"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["titles = df_labeled[\"contract_id\"].unique()\n","train_t, test_t = train_test_split(titles, test_size=0.20, random_state=42)\n","train_t, val_t  = train_test_split(train_t, test_size=0.20, random_state=42)\n","\n","def take(ids): return df_labeled[df_labeled[\"contract_id\"].isin(ids)].reset_index(drop=True)\n","train_df, val_df, test_df = take(train_t), take(val_t), take(test_t)\n","\n","MODEL_NAME  = \"bert-base-uncased\"\n","MAX_LEN     = 512\n","BATCH_SIZE  = 8\n","NUM_LABELS  = len(label_names)\n","\n","tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True)\n","train_ds = ClauseDataset(train_df[\"clause_text\"], train_df[\"y_multi\"], tokenizer, MAX_LEN, NUM_LABELS)\n","val_ds   = ClauseDataset(val_df[\"clause_text\"],   val_df[\"y_multi\"],   tokenizer, MAX_LEN, NUM_LABELS)\n","test_ds  = ClauseDataset(test_df[\"clause_text\"],  test_df[\"y_multi\"],  tokenizer, MAX_LEN, NUM_LABELS)\n","\n","train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n","val_loader   = DataLoader(val_ds,   batch_size=BATCH_SIZE)\n","test_loader  = DataLoader(test_ds,  batch_size=BATCH_SIZE)\n","\n","\n","Y_train_mat = np.array(train_df[\"y_multi\"].tolist())\n","P = Y_train_mat.sum(axis=0)\n","N = len(Y_train_mat)\n","pos_w_np = (N - P) / np.clip(P, 1, None)\n","pos_w = torch.tensor(pos_w_np, dtype=torch.float32, device=device)\n","bce_loss = nn.BCEWithLogitsLoss(pos_weight=pos_w, reduction=\"none\")\n","\n","def loss_fn(logits, targets):\n","    loss = bce_loss(logits, targets)\n","    return loss.mean()\n","\n","CKPT_DIR = \"/content/drive/MyDrive/data_cuad_transformer/ckpt_bert_finetuned\"\n","os.makedirs(CKPT_DIR, exist_ok=True)\n","\n","config = AutoConfig.from_pretrained(\n","    MODEL_NAME,\n","    num_labels=NUM_LABELS,\n","    problem_type=\"multi_label_classification\"\n",")\n","model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, config=config).to(device)\n","optimizer = AdamW(model.parameters(), lr=2e-5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":333,"referenced_widgets":["aa337951aa3b427aa14038a0359859fe","e6685670a08143578e3ba062abd2509a","40e29f8556194ce4a86ea286f2a5f40b","9cf6f0ecf2094425b487af5f7d0cf462","a7175696d4f9484f83a3fe74c1faa716","5c8edbdac53e4208a2b812f0b969033e","0d52f831894c4bf3a598647736d1ca29","6c6cef52fe724612b521f5d13a2c0fc4","f079b8cb27f04541bec84ed39b387b7a","bceb467678a947479005528c9f5a9122","3cb55c545f3146569abce03700f08096","5626ec1a27e843f6b9c2ead882fde64b","bffe7d90a4464ade9508878a36e926bd","277d0b9d28a0445b98f2e6cdb6ef6892","579efaecdf3e42e79163a3a91895fd48","3692b41f934c4229b0c0c5532b30ee24","25727ead43034fb7a8159129ee80d35e","4698876b0de144dbbf2e0a78f614cebf","a4b8244af6b1423e8304de6b2eca4084","d499e8c92a9646f5900c87161f285411","f2062bf200444ead9f3d7f7555f47aa3","cc9e786219d3498a9fab01e71231fda5","6b8d851ac8b1418da211fe09357be446","397c43b52c074f4dafcfcf6810b24e58","14360db516d1493a95f55e5fb85a8ca0","2c0f0b618c8744f589de07167bd3780b","07a17416889f4ef2bd65787dd9cc6eb9","e86bececf8ca4bfbb4e30cf408e3c3ae","c2677e76b394444493640a1b1e030537","dc2fcc3147fe4db6bc4d8ee43307bbf0","65e6ca3d277747e69a612fa321747576","2aae028167484810bb56936b50b81634","b2c0884b8c0b457ba36d887217b6219f","871ec9948de244689dce5f64af54e42c","c43970ce24a649ea9ff7c01c0831552d","74b9226d9cce49639b1a9a83a3e112a0","b804b29717b543299b6176ea12a32bfb","5208691ac1dc460299c29b6492e03f36","e934d7fa6a9a4d55ba7b3a36d054a8b7","98275ace4f7643e29bebbb6d728312f8","1f259ee66f8943b8a70379f3ffbd5ded","17b3d52cccbf4ff7b700c2203a48de3a","76699ff51e074a91b368a0c6ff47738b","a413f1d99746417290eb25a4ff75281f","fd0c649047034feb9e18f75e92183195","ccb28b01548a460cbd1b66ce2c40fede","5a205b3a48c846d2b7e602ad1a0afef7","6bd87ed309c34ba8b6a37edd2e5a479e","536a82a6a1a2425ea2cefe814fbaeb80","9c9e0a938c9d461ba9573c1d6a6854a8","a607efe79ca141f4b1c15d375f6822ab","74d6e30654844e96bc646bbacacd2ad6","93215596f9824fcf8a9f82b4c85ea7f0","ace1bedc57fe47ad95791afc313b52d6","b45bbe429cd44b1c9ba57144fa04540d"]},"id":"7jRJ7Ud-Pijz","executionInfo":{"status":"ok","timestamp":1755089617106,"user_tz":240,"elapsed":21573,"user":{"displayName":"3012 DEVADARSHINI P.T","userId":"12107410435582174408"}},"outputId":"ac4da85e-e1b8-4e7c-9267-fb1a6658494b"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aa337951aa3b427aa14038a0359859fe"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5626ec1a27e843f6b9c2ead882fde64b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6b8d851ac8b1418da211fe09357be446"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"871ec9948de244689dce5f64af54e42c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fd0c649047034feb9e18f75e92183195"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}]},{"cell_type":"code","source":["def multilabel_metrics(y_true, y_pred):\n","    return {\n","        \"micro_f1\": f1_score(y_true, y_pred, average=\"micro\", zero_division=0),\n","        \"macro_f1\": f1_score(y_true, y_pred, average=\"macro\", zero_division=0),\n","        \"micro_precision\": precision_score(y_true, y_pred, average=\"micro\", zero_division=0),\n","        \"micro_recall\": recall_score(y_true, y_pred, average=\"micro\", zero_division=0),\n","        \"macro_precision\": precision_score(y_true, y_pred, average=\"macro\", zero_division=0),\n","        \"macro_recall\": recall_score(y_true, y_pred, average=\"macro\", zero_division=0),\n","    }\n","\n","def find_best_threshold_probs(y_true, y_prob, metric_key=\"micro_f1\"):\n","    best_t, best_stats = 0.5, None\n","    for t in np.linspace(0.1, 0.9, 17):\n","        y_hat = (y_prob >= t).astype(int)\n","        stats = multilabel_metrics(y_true, y_hat)\n","        if best_stats is None or stats[metric_key] > best_stats[metric_key]:\n","            best_t, best_stats = float(t), stats\n","    return best_t, best_stats\n","\n","def infer_loader(model, loader):\n","    model.eval()\n","    all_logits, all_labels = [], []\n","    with torch.no_grad():\n","        for batch in loader:\n","            inputs = {k: v.to(device) for k, v in batch.items() if k != \"labels\"}\n","            labels = batch[\"labels\"].to(device)\n","            logits = model(**inputs).logits\n","            all_logits.append(logits.detach().cpu().numpy())\n","            all_labels.append(labels.detach().cpu().numpy())\n","    return np.vstack(all_logits), np.vstack(all_labels)"],"metadata":{"id":"kQUfkOm8PzyM","executionInfo":{"status":"ok","timestamp":1755089625549,"user_tz":240,"elapsed":34,"user":{"displayName":"3012 DEVADARSHINI P.T","userId":"12107410435582174408"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["max_epochs = 10\n","best_val_micro_f1 = -1.0\n","no_improve = 0\n","patience = 3\n","\n","\n","print(\"Training : \")\n","for epoch in range(1, max_epochs + 1):\n","    model.train()\n","    total_loss = 0.0\n","    for batch in train_loader:\n","        inputs = {k: v.to(device) for k, v in batch.items() if k != \"labels\"}\n","        labels = batch[\"labels\"].to(device)\n","\n","        optimizer.zero_grad()\n","        logits = model(**inputs).logits\n","        loss = loss_fn(logits, labels)\n","        loss.backward()\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","        optimizer.step()\n","\n","        total_loss += loss.item() * labels.size(0)\n","\n","    avg_loss = total_loss / len(train_loader.dataset)\n","\n","    val_logits, y_val = infer_loader(model, val_loader)\n","    val_probs = 1.0 / (1.0 + np.exp(-val_logits))\n","    t_val, stats_val = find_best_threshold_probs(y_val, val_probs)\n","\n","    print(f\"Epoch {epoch} | TrainLoss: {avg_loss:.4f} | Val Micro-F1: {stats_val['micro_f1']:.4f} | Threshold: {t_val:.2f}\")\n","\n","    if stats_val[\"micro_f1\"] > best_val_micro_f1:\n","        best_val_micro_f1 = stats_val[\"micro_f1\"]\n","        model.save_pretrained(CKPT_DIR)\n","        tokenizer.save_pretrained(CKPT_DIR)\n","        with open(os.path.join(CKPT_DIR, \"threshold.json\"), \"w\") as f:\n","            json.dump({\"best_threshold\": float(t_val), \"val_stats\": {k: float(v) for k, v in stats_val.items()}}, f, indent=2)\n","        no_improve = 0\n","    else:\n","        no_improve += 1\n","        if no_improve >= patience:\n","            print(\"Early stopping.\")\n","            break"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_HKaneCzQGOF","executionInfo":{"status":"ok","timestamp":1755090335276,"user_tz":240,"elapsed":702677,"user":{"displayName":"3012 DEVADARSHINI P.T","userId":"12107410435582174408"}},"outputId":"cbaadd8d-e9d9-4028-a617-983507efbd7e"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Training : \n","Epoch 1 | TrainLoss: 0.9583 | Val Micro-F1: 0.4899 | Threshold: 0.45\n","Epoch 2 | TrainLoss: 0.9396 | Val Micro-F1: 0.4850 | Threshold: 0.40\n","Epoch 3 | TrainLoss: 0.9158 | Val Micro-F1: 0.5232 | Threshold: 0.45\n","Epoch 4 | TrainLoss: 0.8571 | Val Micro-F1: 0.5636 | Threshold: 0.45\n","Epoch 5 | TrainLoss: 0.7975 | Val Micro-F1: 0.5795 | Threshold: 0.45\n","Epoch 6 | TrainLoss: 0.7422 | Val Micro-F1: 0.5964 | Threshold: 0.45\n","Epoch 7 | TrainLoss: 0.7001 | Val Micro-F1: 0.6036 | Threshold: 0.45\n","Epoch 8 | TrainLoss: 0.6573 | Val Micro-F1: 0.6109 | Threshold: 0.45\n","Epoch 9 | TrainLoss: 0.6258 | Val Micro-F1: 0.6124 | Threshold: 0.40\n","Epoch 10 | TrainLoss: 0.5939 | Val Micro-F1: 0.6256 | Threshold: 0.40\n"]}]},{"cell_type":"code","source":["with open(os.path.join(CKPT_DIR, \"threshold.json\"), \"r\") as f:\n","    meta = json.load(f)\n","best_t = float(meta[\"best_threshold\"])\n","best_val_stats = {k: float(v) for k, v in meta[\"val_stats\"].items()}\n","\n","best_model = AutoModelForSequenceClassification.from_pretrained(CKPT_DIR).to(device)\n","\n","test_logits, y_test = infer_loader(best_model, test_loader)\n","test_probs = 1.0 / (1.0 + np.exp(-test_logits))\n","y_test_hat = (test_probs >= best_t).astype(int)\n","\n","test_stats = multilabel_metrics(y_test, y_test_hat)\n","\n","print(\"BERT F1 Score (Micro):\", f1_score(y_test, y_test_hat, average=\"micro\", zero_division=0))\n","print(\"VAL :\", {k: round(v, 4) for k, v in best_val_stats.items()})\n","print(\"TEST:\", {k: round(v, 4) for k, v in test_stats.items()})"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AZOv6W5Be7Kz","executionInfo":{"status":"ok","timestamp":1755090810526,"user_tz":240,"elapsed":9845,"user":{"displayName":"3012 DEVADARSHINI P.T","userId":"12107410435582174408"}},"outputId":"9d066242-4100-4981-c5e4-6cfaa8179b52"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["BERT F1 Score (Micro): 0.5997248968363136\n","VAL : {'micro_f1': 0.6256, 'macro_f1': 0.4957, 'micro_precision': 0.4986, 'micro_recall': 0.8392, 'macro_precision': 0.4125, 'macro_recall': 0.7789}\n","TEST: {'micro_f1': 0.5997, 'macro_f1': 0.4785, 'micro_precision': 0.4727, 'micro_recall': 0.8202, 'macro_precision': 0.3916, 'macro_recall': 0.7407}\n"]}]},{"cell_type":"markdown","source":["### Sample Output"],"metadata":{"id":"lfXDx0WClBIn"}},{"cell_type":"code","source":["def names_from_vec(vec, names):\n","    return [names[i] for i, v in enumerate(vec) if int(v) == 1]\n","\n","np.random.seed(42)\n","k = 3\n","idxs = np.random.choice(len(test_df), size=min(k, len(test_df)), replace=False)\n","\n","for idx in idxs:\n","    clause = test_df[\"clause_text\"].iloc[idx]\n","    clause_short = (clause[:600] + \"...\") if len(clause) > 600 else clause\n","\n","    true_labels = names_from_vec(y_test[idx], label_names)\n","    pred_labels = names_from_vec(y_test_hat[idx], label_names)\n","\n","    print(\"\\n— Clause —\")\n","    print(clause_short, \"\\n\")\n","    print(\" True:\", true_labels)\n","    print(\" Pred (BERT):\", pred_labels)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5n8MQJ3Wk9ER","executionInfo":{"status":"ok","timestamp":1755091071627,"user_tz":240,"elapsed":7,"user":{"displayName":"3012 DEVADARSHINI P.T","userId":"12107410435582174408"}},"outputId":"25f343e8-a0e3-49f0-e4cd-a7056176be0f"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","— Clause —\n","Exhibit 10.5 STRATEGIC ALLIANCE AGREEMENT ---------------------------- THIS STRATEGIC ALLIANCE AGREEMENT (this \"Agreement\") is made as of 31 December, --------- 1996, between NORTHERN TELECOM LIMITED, a Canadian corporation (\"NTL\"), and --- ENTRUST TECHNOLOGIES INC., a Maryland corporation (\"ETI\"). --- WHEREAS, pursuant to an asset transfer agreement between NTL and Entrust Technologies Limited of even date (the \"NTL Transfer Agreement\") and an asset ---------------------- transfer agreement between Northern Telecom Inc. and ETI of even date, the Entrust Technology (as defined herein) has been... \n","\n"," True: ['Affiliate License-Licensee', 'Affiliate License-Licensor', 'Agreement Date', 'Anti-Assignment', 'Cap On Liability', 'Covenant Not To Sue', 'Effective Date', 'Governing Law', 'Insurance', 'Joint Ip Ownership', 'Liquidated Damages', 'No-Solicit Of Customers', 'Notice Period To Terminate Renewal', 'Post-Termination Services', 'Unlimited/All-You-Can-Eat-License', 'Volume Restriction']\n"," Pred (BERT): ['Agreement Date', 'Cap On Liability', 'Covenant Not To Sue', 'Effective Date', 'Exclusivity', 'Insurance', 'Post-Termination Services', 'Revenue/Profit Sharing', 'Third Party Beneficiary']\n","\n","— Clause —\n","CONFIDENTIAL PORTIONS OMITTED EXHIBIT 10.16 [LOGO OF TEAM SABCO APPEARS HERE] SPONSORSHIP AGREEMENT THIS SPONSORSHIP AGREEMENT (hereinafter the \"Agreement) is made and entered into this 19th day of December 1997, by and between SABCO RACING, INC., a North Carolina corporation with a place of business in Iredell County, North Carolina (hereinafter Sabco), and Prolong Super Lubricants, Anaheim, Calif. (Hereinafter to be referred to as \"Prolong\"); WITNESSETH: WHEREAS, Sabco is engaged in the business of operating NASCAR Winston Cup Series race cars and wishes to provide advertising space and adve... \n","\n"," True: ['Agreement Date', 'Anti-Assignment', 'Effective Date', 'Expiration Date', 'Governing Law', 'Insurance', 'Ip Ownership Assignment', 'Post-Termination Services']\n"," Pred (BERT): ['Agreement Date', 'Effective Date', 'Exclusivity', 'Governing Law', 'Ip Ownership Assignment', 'Non-Transferable License', 'Post-Termination Services', 'Third Party Beneficiary']\n","\n","— Clause —\n","925 West Georgia Street Suite 1820 Vancouver, British Columbia Canada V6C 3L2 Facsimile: 604-632-1730 PROMOTION AGREEMENT (the \"Agreement\") This agreement (the \"Agreement\") is made between Charity Tunes Inc., a British Columbia corporation with registered office located at Suite 1800, 925 West Georgia Street, Vancouver, British Columbia, Canada V6C 3L2 (\"Charity Tunes\") and ConAgra Foods Canada Inc. (\"Sponsor\") a Canada corporation, 5935 Airport Rd, Suite 405, Mississauga, Ontario, Canada L4V 1W5. WHEREAS as a new initiative, Charity Tunes and Sponsor will enter into a promotional partnership,... \n","\n"," True: ['Agreement Date', 'Anti-Assignment', 'Effective Date', 'Expiration Date', 'Insurance', 'Post-Termination Services', 'Warranty Duration']\n"," Pred (BERT): ['Agreement Date', 'Anti-Assignment', 'Audit Rights', 'Cap On Liability', 'Competitive Restriction Exception', 'Covenant Not To Sue', 'Effective Date', 'Exclusivity', 'Expiration Date', 'Governing Law', 'Insurance', 'Ip Ownership Assignment', 'Liquidated Damages', 'Most Favored Nation', 'No-Solicit Of Customers', 'Non-Transferable License', 'Notice Period To Terminate Renewal', 'Parties', 'Post-Termination Services', 'Renewal Term', 'Revenue/Profit Sharing', 'Rofr/Rofo/Rofn', 'Source Code Escrow', 'Unlimited/All-You-Can-Eat-License', 'Volume Restriction', 'Warranty Duration', 'label_40']\n"]}]},{"cell_type":"markdown","source":["### RoBertA"],"metadata":{"id":"xkgYpN4jkUpp"}},{"cell_type":"code","source":["import os, json, numpy as np, pandas as pd\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader\n","from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoConfig\n","from torch.optim import AdamW\n","from sklearn.metrics import f1_score, precision_score, recall_score\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(\"Using device:\", device)\n","\n","df_labeled = pd.read_pickle(\"/content/drive/MyDrive/data_cuad_transformer/df_labeled.pkl\")\n","import pickle\n","with open(\"/content/drive/MyDrive/data_cuad_transformer/label_names.pkl\", \"rb\") as f:\n","    label_names = pickle.load(f)\n","\n","drop_idx = 9\n","label_names = [lab for i, lab in enumerate(label_names) if i != drop_idx]\n","TARGET_L = len(label_names)\n","\n","def to_fixed(v, L=TARGET_L):\n","    a = np.asarray(v, dtype=np.float32).ravel()\n","    if a.shape[0] >= L:\n","        return a[:L].tolist()\n","    else:\n","        return np.pad(a, (0, L - a.shape[0]), constant_values=0).tolist()\n","\n","df_labeled[\"y_multi\"] = df_labeled[\"y_multi\"].apply(to_fixed)\n","lens = df_labeled[\"y_multi\"].map(len).value_counts()\n","\n","\n","class ClauseDataset(Dataset):\n","    def __init__(self, texts, labels, tokenizer, max_len=512, num_labels=None):\n","        self.texts = list(texts)\n","        L = num_labels if num_labels is not None else TARGET_L\n","        self.labels = np.stack([to_fixed(y, L) for y in labels], axis=0).astype(np.float32)\n","        self.tokenizer = tokenizer\n","        self.max_len = max_len\n","\n","    def __len__(self): return len(self.texts)\n","\n","    def __getitem__(self, idx):\n","        enc = self.tokenizer(\n","            self.texts[idx],\n","            truncation=True,\n","            padding=\"max_length\",\n","            max_length=self.max_len,\n","            return_tensors=\"pt\"\n","        )\n","        item = {k: v.squeeze(0) for k, v in enc.items()}\n","        item[\"labels\"] = torch.tensor(self.labels[idx], dtype=torch.float32)\n","        return item"],"metadata":{"id":"vx6mAJtETBcq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1755092242249,"user_tz":240,"elapsed":160,"user":{"displayName":"3012 DEVADARSHINI P.T","userId":"12107410435582174408"}},"outputId":"7a755438-2c5d-42cf-a12d-9ad59477b544"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["Using device: cuda\n"]}]},{"cell_type":"markdown","source":["### Split dataset"],"metadata":{"id":"RSoAEXvhWlG8"}},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","titles = df_labeled[\"contract_id\"].unique()\n","train_t, test_t = train_test_split(titles, test_size=0.2, random_state=42)\n","train_t, val_t  = train_test_split(train_t, test_size=0.2, random_state=42)\n","\n","def take(ids): return df_labeled[df_labeled[\"contract_id\"].isin(ids)].reset_index(drop=True)\n","train_df, val_df, test_df = take(train_t), take(val_t), take(test_t)\n","\n","MODEL_NAME = \"roberta-base\"\n","MAX_LEN = 512\n","BATCH_SIZE = 8\n","NUM_LABELS = len(label_names)\n","\n","tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True)\n","train_ds = ClauseDataset(train_df[\"clause_text\"], train_df[\"y_multi\"], tokenizer, MAX_LEN)\n","val_ds   = ClauseDataset(val_df[\"clause_text\"], val_df[\"y_multi\"], tokenizer, MAX_LEN)\n","test_ds  = ClauseDataset(test_df[\"clause_text\"], test_df[\"y_multi\"], tokenizer, MAX_LEN)\n","\n","train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n","val_loader   = DataLoader(val_ds, batch_size=BATCH_SIZE)\n","test_loader  = DataLoader(test_ds, batch_size=BATCH_SIZE)\n","\n","class ClassBalancedFocalLoss(nn.Module):\n","    def __init__(self, beta=0.9999, gamma=2.0, class_counts=None, device='cpu'):\n","        super().__init__()\n","        effective_num = 1.0 - torch.pow(beta, class_counts)\n","        weights = (1.0 - beta) / (effective_num + 1e-8)\n","        weights = weights / weights.sum() * len(class_counts)\n","        self.weights = weights.to(device)\n","        self.gamma = gamma\n","\n","    def forward(self, logits, targets):\n","        probs = torch.sigmoid(logits)\n","        ce_loss = F.binary_cross_entropy_with_logits(logits, targets, reduction='none')\n","        p_t = probs * targets + (1 - probs) * (1 - targets)\n","        loss = ((1 - p_t) ** self.gamma) * ce_loss * self.weights\n","        return loss.mean()\n","\n","CKPT_DIR = \"/content/drive/MyDrive/data_cuad_transformer/ckpt_roberta_finetuned\"\n","os.makedirs(CKPT_DIR, exist_ok=True)\n","\n","Y_train_mat = np.array(train_df[\"y_multi\"].tolist())\n","class_counts = Y_train_mat.sum(axis=0)\n","loss_fn = ClassBalancedFocalLoss(class_counts=torch.tensor(class_counts), device=device)"],"metadata":{"id":"U8lvoagnWTw6","executionInfo":{"status":"ok","timestamp":1755092254193,"user_tz":240,"elapsed":545,"user":{"displayName":"3012 DEVADARSHINI P.T","userId":"12107410435582174408"}}},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":["### Fine tuning RoBertA"],"metadata":{"id":"v8Yeq9-sWzq5"}},{"cell_type":"code","source":["config = AutoConfig.from_pretrained(MODEL_NAME, num_labels=NUM_LABELS, problem_type=\"multi_label_classification\")\n","model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, config=config).to(device)\n","optimizer = AdamW(model.parameters(), lr=2e-5)"],"metadata":{"id":"IfMo-_XgWyzB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1755092266071,"user_tz":240,"elapsed":903,"user":{"displayName":"3012 DEVADARSHINI P.T","userId":"12107410435582174408"}},"outputId":"944979c3-892e-400e-882e-7747ef6e842b"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}]},{"cell_type":"markdown","source":["### Evaluation and threshold tuning"],"metadata":{"id":"CXXQ3Om0XTxR"}},{"cell_type":"code","source":["def multilabel_metrics(y_true, y_pred):\n","    return {\n","        \"micro_f1\": f1_score(y_true, y_pred, average=\"micro\", zero_division=0),\n","        \"macro_f1\": f1_score(y_true, y_pred, average=\"macro\", zero_division=0),\n","        \"micro_precision\": precision_score(y_true, y_pred, average=\"micro\", zero_division=0),\n","        \"micro_recall\": recall_score(y_true, y_pred, average=\"micro\", zero_division=0),\n","        \"macro_precision\": precision_score(y_true, y_pred, average=\"macro\", zero_division=0),\n","        \"macro_recall\": recall_score(y_true, y_pred, average=\"macro\", zero_division=0),\n","    }\n","\n","def find_best_threshold_probs(y_true, y_prob, metric_key=\"micro_f1\"):\n","    best_t, best_stats = 0.5, None\n","    for t in np.linspace(0.1, 0.9, 17):\n","        y_hat = (y_prob >= t).astype(int)\n","        stats = multilabel_metrics(y_true, y_hat)\n","        if best_stats is None or stats[metric_key] > best_stats[metric_key]:\n","            best_t, best_stats = float(t), stats\n","    return best_t, best_stats\n","\n","def infer_loader(model, loader):\n","    model.eval()\n","    all_logits, all_labels = [], []\n","    with torch.no_grad():\n","        for batch in loader:\n","            inputs = {k: v.to(device) for k, v in batch.items() if k != \"labels\"}\n","            labels = batch[\"labels\"].to(device)\n","            logits = model(**inputs).logits\n","            all_logits.append(logits.detach().cpu().numpy())\n","            all_labels.append(labels.detach().cpu().numpy())\n","    return np.vstack(all_logits), np.vstack(all_labels)"],"metadata":{"id":"SMRJPiq3XOqZ","executionInfo":{"status":"ok","timestamp":1755092270963,"user_tz":240,"elapsed":4,"user":{"displayName":"3012 DEVADARSHINI P.T","userId":"12107410435582174408"}}},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":["### Training and Evaluation"],"metadata":{"id":"Deziy_F6XopJ"}},{"cell_type":"code","source":["max_epochs = 10\n","best_val_micro_f1 = -1.0\n","no_improve = 0\n","patience = 3\n","\n","print(\"Training : \")\n","for epoch in range(1, max_epochs + 1):\n","    model.train()\n","    total_loss = 0.0\n","    for batch in train_loader:\n","        inputs = {k: v.to(device) for k, v in batch.items() if k != \"labels\"}\n","        labels = batch[\"labels\"].to(device)\n","        optimizer.zero_grad()\n","        logits = model(**inputs).logits\n","        loss = loss_fn(logits, labels)\n","        loss.backward()\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","        optimizer.step()\n","        total_loss += loss.item() * labels.size(0)\n","\n","    avg_loss = total_loss / len(train_loader.dataset)\n","    val_logits, y_val = infer_loader(model, val_loader)\n","    val_probs = 1 / (1 + np.exp(-val_logits))\n","    t_val, stats_val = find_best_threshold_probs(y_val, val_probs)\n","\n","    print(f\"Epoch {epoch} | Loss: {avg_loss:.4f} | Val Micro-F1: {stats_val['micro_f1']:.4f} | Threshold: {t_val:.2f}\")\n","\n","    if stats_val[\"micro_f1\"] > best_val_micro_f1:\n","        best_val_micro_f1 = stats_val[\"micro_f1\"]\n","        model.save_pretrained(CKPT_DIR)\n","        tokenizer.save_pretrained(CKPT_DIR)\n","        with open(os.path.join(CKPT_DIR, \"threshold.json\"), \"w\") as f:\n","            json.dump({\"best_threshold\": float(t_val), \"val_stats\": stats_val}, f, indent=2)\n","        no_improve = 0\n","    else:\n","        no_improve += 1\n","        if no_improve >= patience:\n","            print(\"Early stopping.\")\n","            break"],"metadata":{"id":"HSzzV_qtXntN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1755092958722,"user_tz":240,"elapsed":683213,"user":{"displayName":"3012 DEVADARSHINI P.T","userId":"12107410435582174408"}},"outputId":"101803dc-8643-4a51-c2e6-d8e721b666f7"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["Training : \n","Epoch 1 | Loss: 0.0948 | Val Micro-F1: 0.6657 | Threshold: 0.45\n","Epoch 2 | Loss: 0.0742 | Val Micro-F1: 0.6750 | Threshold: 0.40\n","Epoch 3 | Loss: 0.0744 | Val Micro-F1: 0.6753 | Threshold: 0.45\n","Epoch 4 | Loss: 0.0741 | Val Micro-F1: 0.6718 | Threshold: 0.40\n","Epoch 5 | Loss: 0.0720 | Val Micro-F1: 0.6790 | Threshold: 0.40\n","Epoch 6 | Loss: 0.0713 | Val Micro-F1: 0.6967 | Threshold: 0.45\n","Epoch 7 | Loss: 0.0686 | Val Micro-F1: 0.7196 | Threshold: 0.45\n","Epoch 8 | Loss: 0.0647 | Val Micro-F1: 0.7161 | Threshold: 0.45\n","Epoch 9 | Loss: 0.0615 | Val Micro-F1: 0.7123 | Threshold: 0.40\n","Epoch 10 | Loss: 0.0556 | Val Micro-F1: 0.7376 | Threshold: 0.40\n"]}]},{"cell_type":"code","source":["from transformers import AutoModelForSequenceClassification\n","\n","with open(os.path.join(CKPT_DIR, \"threshold.json\"), \"r\") as f:\n","    meta_rb = json.load(f)\n","\n","best_t_rb = float(meta_rb[\"best_threshold\"])\n","best_val_stats_rb = {k: float(v) for k, v in meta_rb[\"val_stats\"].items()}\n","\n","roberta_best = AutoModelForSequenceClassification.from_pretrained(CKPT_DIR).to(device)\n","\n","test_logits_rb, y_test = infer_loader(roberta_best, test_loader)\n","test_probs_rb = 1.0 / (1.0 + np.exp(-test_logits_rb))\n","y_test_hat_roberta = (test_probs_rb >= best_t_rb).astype(int)\n","\n","test_stats_rb = multilabel_metrics(y_test, y_test_hat_roberta)\n","\n","print(\"RoBERTa F1 Score (Micro):\", f1_score(y_test, y_test_hat_roberta, average=\"micro\", zero_division=0))\n","print(\"VAL :\", {k: round(v, 4) for k, v in best_val_stats_rb.items()})\n","print(\"TEST:\", {k: round(v, 4) for k, v in test_stats_rb.items()})"],"metadata":{"id":"bb4QIzZJXxMf","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1755093044758,"user_tz":240,"elapsed":12759,"user":{"displayName":"3012 DEVADARSHINI P.T","userId":"12107410435582174408"}},"outputId":"cde17a44-3c00-4132-9f2f-34cfbea04288"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["RoBERTa F1 Score (Micro): 0.6829752066115703\n","VAL : {'micro_f1': 0.7376, 'macro_f1': 0.4636, 'micro_precision': 0.6672, 'micro_recall': 0.8248, 'macro_precision': 0.429, 'macro_recall': 0.5358}\n","TEST: {'micro_f1': 0.683, 'macro_f1': 0.4322, 'micro_precision': 0.5988, 'micro_recall': 0.7946, 'macro_precision': 0.3972, 'macro_recall': 0.524}\n"]}]},{"cell_type":"markdown","source":["### Sample Output :"],"metadata":{"id":"aTaPGsb8rHdP"}},{"cell_type":"code","source":["def names_from_vec(vec, names):\n","    return [names[i] for i, v in enumerate(vec) if int(v) == 1]\n","\n","def show_roberta_preds(k=3, seed=42):\n","\n","    y_hat_roberta = globals().get(\"y_test_hat_roberta\", globals().get(\"y_test_hat\"))\n","    assert y_hat_roberta is not None, \"Run RoBERTa eval first to create y_test_hat (or y_test_hat_roberta).\"\n","\n","    np.random.seed(seed)\n","    k = min(k, len(test_df))\n","    idxs = np.random.choice(len(test_df), size=k, replace=False)\n","\n","    for idx in idxs:\n","        clause = test_df[\"clause_text\"].iloc[idx]\n","        clause_short = (clause[:600] + \"...\") if len(clause) > 600 else clause\n","\n","        true_labels = names_from_vec(y_test[idx], label_names)\n","        pred_labels = names_from_vec(y_hat_roberta[idx], label_names)\n","\n","        print(\"\\n— Clause —\")\n","        print(clause_short, \"\\n\")\n","        print(\" True:\", true_labels)\n","        print(\" Pred (RoBERTa):\", pred_labels)\n","\n","show_roberta_preds(k=3, seed=42)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lYstXMxmrMFN","executionInfo":{"status":"ok","timestamp":1755093122022,"user_tz":240,"elapsed":10,"user":{"displayName":"3012 DEVADARSHINI P.T","userId":"12107410435582174408"}},"outputId":"89b957fd-ab9b-4d09-e82c-fb72622eba03"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","— Clause —\n","Exhibit 10.5 STRATEGIC ALLIANCE AGREEMENT ---------------------------- THIS STRATEGIC ALLIANCE AGREEMENT (this \"Agreement\") is made as of 31 December, --------- 1996, between NORTHERN TELECOM LIMITED, a Canadian corporation (\"NTL\"), and --- ENTRUST TECHNOLOGIES INC., a Maryland corporation (\"ETI\"). --- WHEREAS, pursuant to an asset transfer agreement between NTL and Entrust Technologies Limited of even date (the \"NTL Transfer Agreement\") and an asset ---------------------- transfer agreement between Northern Telecom Inc. and ETI of even date, the Entrust Technology (as defined herein) has been... \n","\n"," True: ['Affiliate License-Licensee', 'Affiliate License-Licensor', 'Agreement Date', 'Anti-Assignment', 'Cap On Liability', 'Covenant Not To Sue', 'Exclusivity', 'Insurance', 'Ip Ownership Assignment', 'License Grant', 'Minimum Commitment', 'No-Solicit Of Employees', 'Parties', 'Price Restrictions', 'Volume Restriction', 'Warranty Duration']\n"," Pred (RoBERTa): ['Affiliate License-Licensee', 'Agreement Date', 'Anti-Assignment', 'Audit Rights', 'Cap On Liability', 'Change Of Control', 'Competitive Restriction Exception', 'Covenant Not To Sue', 'Exclusivity', 'Expiration Date', 'Governing Law', 'Insurance', 'Ip Ownership Assignment', 'Irrevocable Or Perpetual License', 'Joint Ip Ownership', 'License Grant', 'Liquidated Damages', 'Minimum Commitment', 'No-Solicit Of Customers', 'Non-Transferable License', 'Parties', 'Price Restrictions', 'Renewal Term', 'Rofr/Rofo/Rofn', 'Source Code Escrow', 'Termination For Convenience', 'Uncapped Liability', 'Volume Restriction']\n","\n","— Clause —\n","CONFIDENTIAL PORTIONS OMITTED EXHIBIT 10.16 [LOGO OF TEAM SABCO APPEARS HERE] SPONSORSHIP AGREEMENT THIS SPONSORSHIP AGREEMENT (hereinafter the \"Agreement) is made and entered into this 19th day of December 1997, by and between SABCO RACING, INC., a North Carolina corporation with a place of business in Iredell County, North Carolina (hereinafter Sabco), and Prolong Super Lubricants, Anaheim, Calif. (Hereinafter to be referred to as \"Prolong\"); WITNESSETH: WHEREAS, Sabco is engaged in the business of operating NASCAR Winston Cup Series race cars and wishes to provide advertising space and adve... \n","\n"," True: ['Agreement Date', 'Anti-Assignment', 'Exclusivity', 'Governing Law', 'Insurance', 'Ip Ownership Assignment', 'Irrevocable Or Perpetual License', 'Price Restrictions']\n"," Pred (RoBERTa): ['Agreement Date', 'Anti-Assignment', 'Audit Rights', 'Cap On Liability', 'Exclusivity', 'Expiration Date', 'Governing Law', 'Insurance', 'Ip Ownership Assignment', 'Irrevocable Or Perpetual License', 'Minimum Commitment', 'No-Solicit Of Customers', 'Post-Termination Services', 'Price Restrictions', 'Renewal Term', 'Rofr/Rofo/Rofn', 'Source Code Escrow', 'Uncapped Liability']\n","\n","— Clause —\n","925 West Georgia Street Suite 1820 Vancouver, British Columbia Canada V6C 3L2 Facsimile: 604-632-1730 PROMOTION AGREEMENT (the \"Agreement\") This agreement (the \"Agreement\") is made between Charity Tunes Inc., a British Columbia corporation with registered office located at Suite 1800, 925 West Georgia Street, Vancouver, British Columbia, Canada V6C 3L2 (\"Charity Tunes\") and ConAgra Foods Canada Inc. (\"Sponsor\") a Canada corporation, 5935 Airport Rd, Suite 405, Mississauga, Ontario, Canada L4V 1W5. WHEREAS as a new initiative, Charity Tunes and Sponsor will enter into a promotional partnership,... \n","\n"," True: ['Agreement Date', 'Anti-Assignment', 'Exclusivity', 'Governing Law', 'Ip Ownership Assignment', 'Price Restrictions']\n"," Pred (RoBERTa): ['Agreement Date', 'Anti-Assignment', 'Audit Rights', 'Cap On Liability', 'Exclusivity', 'Expiration Date', 'Insurance', 'Ip Ownership Assignment', 'Minimum Commitment', 'No-Solicit Of Customers', 'Price Restrictions', 'Renewal Term', 'Rofr/Rofo/Rofn', 'Source Code Escrow']\n"]}]},{"cell_type":"markdown","source":["### Legal Bert"],"metadata":{"id":"d9WsohdVdzVz"}},{"cell_type":"code","source":["import os, json, numpy as np, pandas as pd\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader\n","from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoConfig\n","from torch.optim import AdamW\n","from sklearn.metrics import f1_score, precision_score, recall_score\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(\"Using device:\", device)\n","\n","df_labeled = pd.read_pickle(\"/content/drive/MyDrive/data_cuad_transformer/df_labeled.pkl\")\n","import pickle\n","with open(\"/content/drive/MyDrive/data_cuad_transformer/label_names.pkl\", \"rb\") as f:\n","    label_names = pickle.load(f)\n","\n","df_labeled[\"y_multi\"] = df_labeled[\"y_multi\"].apply(lambda v: np.asarray(v, dtype=np.float32))\n","y_lengths = df_labeled[\"y_multi\"].map(lambda v: v.shape[0]).unique()\n","if len(y_lengths) != 1:\n","    raise ValueError(f\"Inconsistent y_multi lengths across rows: {y_lengths}\")\n","\n","TRUE_NUM_LABELS = int(y_lengths[0])\n","\n","if len(label_names) != TRUE_NUM_LABELS:\n","    print(f\"label_names len={len(label_names)}\")\n","    if len(label_names) > TRUE_NUM_LABELS:\n","        label_names = list(label_names)[:TRUE_NUM_LABELS]\n","    else:\n","        label_names = list(label_names) + [f\"label_{i}\" for i in range(len(label_names), TRUE_NUM_LABELS)]\n","\n","NUM_LABELS = TRUE_NUM_LABELS\n","\n","def _align_to_n(vec, n):\n","    vec = np.asarray(vec, dtype=np.float32)\n","    if vec.ndim == 1:\n","        if vec.shape[0] > n:\n","            return vec[:n]\n","        if vec.shape[0] < n:\n","            return np.pad(vec, (0, n - vec.shape[0]), constant_values=0.0)\n","        return vec\n","    if vec.shape[1] > n:\n","        return vec[:, :n]\n","    if vec.shape[1] < n:\n","        pad = np.zeros((vec.shape[0], n - vec.shape[1]), dtype=np.float32)\n","        return np.hstack([vec, pad])\n","    return vec"],"metadata":{"id":"5c7fOY2JYe_v","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1755093456905,"user_tz":240,"elapsed":184,"user":{"displayName":"3012 DEVADARSHINI P.T","userId":"12107410435582174408"}},"outputId":"866cbd15-087c-4802-e9b4-7499027928e2"},"execution_count":38,"outputs":[{"output_type":"stream","name":"stdout","text":["Using device: cuda\n","label_names len=40\n"]}]},{"cell_type":"code","source":["class ClauseDataset(Dataset):\n","    def __init__(self, texts, labels, tokenizer, max_len=512, num_labels=None):\n","        self.texts = list(texts)\n","        arr = np.array(list(labels), dtype=np.float32)\n","        if num_labels is not None:\n","            arr = _align_to_n(arr, num_labels)\n","        self.labels = arr\n","        self.tokenizer = tokenizer\n","        self.max_len = max_len\n","\n","    def __len__(self): return len(self.texts)\n","\n","    def __getitem__(self, idx):\n","        enc = self.tokenizer(\n","            self.texts[idx],\n","            truncation=True,\n","            padding=\"max_length\",\n","            max_length=self.max_len,\n","            return_tensors=\"pt\"\n","        )\n","        item = {k: v.squeeze(0) for k, v in enc.items()}\n","        item[\"labels\"] = torch.tensor(self.labels[idx], dtype=torch.float32)\n","        return item"],"metadata":{"id":"funuiZq4d626","executionInfo":{"status":"ok","timestamp":1755093459198,"user_tz":240,"elapsed":45,"user":{"displayName":"3012 DEVADARSHINI P.T","userId":"12107410435582174408"}}},"execution_count":39,"outputs":[]},{"cell_type":"markdown","source":["## Split dataset"],"metadata":{"id":"hUu-2uOrrq0y"}},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","titles = df_labeled[\"contract_id\"].unique()\n","train_t, test_t = train_test_split(titles, test_size=0.2, random_state=42)\n","train_t, val_t  = train_test_split(train_t, test_size=0.2, random_state=42)\n","\n","def take(ids): return df_labeled[df_labeled[\"contract_id\"].isin(ids)].reset_index(drop=True)\n","train_df, val_df, test_df = take(train_t), take(val_t), take(test_t)\n","\n","MODEL_NAME = \"nlpaueb/legal-bert-base-uncased\"\n","MAX_LEN = 512\n","BATCH_SIZE = 8\n","NUM_LABELS = len(label_names)\n","\n","tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True)\n","train_ds = ClauseDataset(train_df[\"clause_text\"], train_df[\"y_multi\"], tokenizer, MAX_LEN, num_labels=NUM_LABELS)\n","val_ds   = ClauseDataset(val_df[\"clause_text\"],   val_df[\"y_multi\"],   tokenizer, MAX_LEN, num_labels=NUM_LABELS)\n","test_ds  = ClauseDataset(test_df[\"clause_text\"],  test_df[\"y_multi\"],  tokenizer, MAX_LEN, num_labels=NUM_LABELS)\n","\n","train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n","val_loader   = DataLoader(val_ds,   batch_size=BATCH_SIZE)\n","test_loader  = DataLoader(test_ds,  batch_size=BATCH_SIZE)\n","\n","class ClassBalancedFocalLoss(nn.Module):\n","    def __init__(self, beta=0.9999, gamma=2.0, class_counts=None, device='cpu'):\n","        super().__init__()\n","        effective_num = 1.0 - torch.pow(beta, class_counts)\n","        weights = (1.0 - beta) / (effective_num + 1e-8)\n","        weights = weights / weights.sum() * len(class_counts)\n","        self.weights = weights.to(device)\n","        self.gamma = gamma\n","\n","    def forward(self, logits, targets):\n","        probs = torch.sigmoid(logits)\n","        ce_loss = F.binary_cross_entropy_with_logits(logits, targets, reduction='none')\n","        p_t = probs * targets + (1 - probs) * (1 - targets)\n","        loss = ((1 - p_t) ** self.gamma) * ce_loss * self.weights\n","        return loss.mean()\n","\n","CKPT_DIR = \"/content/drive/MyDrive/data_cuad_transformer/ckpt_legalbert_finetuned\"\n","os.makedirs(CKPT_DIR, exist_ok=True)\n","\n","Y_train_mat = np.array(list(train_df[\"y_multi\"]), dtype=np.float32)\n","Y_train_mat = _align_to_n(Y_train_mat, NUM_LABELS)\n","class_counts = Y_train_mat.sum(axis=0)\n","\n","config = AutoConfig.from_pretrained(MODEL_NAME, num_labels=NUM_LABELS, problem_type=\"multi_label_classification\")\n","model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, config=config).to(device)\n","optimizer = AdamW(model.parameters(), lr=2e-5)"],"metadata":{"id":"J1dIYU1jebTs","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1755093533185,"user_tz":240,"elapsed":1143,"user":{"displayName":"3012 DEVADARSHINI P.T","userId":"12107410435582174408"}},"outputId":"0e3dcc62-1433-4fa1-bb00-162248bfa2c2"},"execution_count":42,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of BertForSequenceClassification were not initialized from the model checkpoint at nlpaueb/legal-bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}]},{"cell_type":"markdown","source":["## Metrics and Fine Tuning"],"metadata":{"id":"3IvnaQ2pr1R7"}},{"cell_type":"code","source":["def multilabel_metrics(y_true, y_pred):\n","    return {\n","        \"micro_f1\": f1_score(y_true, y_pred, average=\"micro\", zero_division=0),\n","        \"macro_f1\": f1_score(y_true, y_pred, average=\"macro\", zero_division=0),\n","        \"micro_precision\": precision_score(y_true, y_pred, average=\"micro\", zero_division=0),\n","        \"micro_recall\": recall_score(y_true, y_pred, average=\"micro\", zero_division=0),\n","        \"macro_precision\": precision_score(y_true, y_pred, average=\"macro\", zero_division=0),\n","        \"macro_recall\": recall_score(y_true, y_pred, average=\"macro\", zero_division=0),\n","    }\n","\n","def find_best_threshold_probs(y_true, y_prob, metric_key=\"micro_f1\"):\n","    best_t, best_stats = 0.5, None\n","    for t in np.linspace(0.1, 0.9, 17):\n","        y_hat = (y_prob >= t).astype(int)\n","        stats = multilabel_metrics(y_true, y_hat)\n","        if best_stats is None or stats[metric_key] > best_stats[metric_key]:\n","            best_t, best_stats = float(t), stats\n","    return best_t, best_stats\n","\n","def infer_loader(model, loader):\n","    model.eval()\n","    all_logits, all_labels = [], []\n","    with torch.no_grad():\n","        for batch in loader:\n","            inputs = {k: v.to(device) for k, v in batch.items() if k != \"labels\"}\n","            labels = batch[\"labels\"].to(device)\n","            logits = model(**inputs).logits\n","            all_logits.append(logits.detach().cpu().numpy())\n","            all_labels.append(labels.detach().cpu().numpy())\n","    return np.vstack(all_logits), np.vstack(all_labels)"],"metadata":{"id":"UitT-8Uvekg8","executionInfo":{"status":"ok","timestamp":1755093535458,"user_tz":240,"elapsed":3,"user":{"displayName":"3012 DEVADARSHINI P.T","userId":"12107410435582174408"}}},"execution_count":43,"outputs":[]},{"cell_type":"markdown","source":["## Training"],"metadata":{"id":"7C_73zWcr_bY"}},{"cell_type":"code","source":["max_epochs = 10\n","best_val_micro_f1 = -1.0\n","no_improve = 0\n","patience = 3\n","\n","print(\"Training :\")\n","for epoch in range(1, max_epochs + 1):\n","    model.train()\n","    total_loss = 0.0\n","    for batch in train_loader:\n","        inputs = {k: v.to(device) for k, v in batch.items() if k != \"labels\"}\n","        labels = batch[\"labels\"].to(device)\n","        optimizer.zero_grad()\n","        logits = model(**inputs).logits\n","        loss = loss_fn(logits, labels)\n","        loss.backward()\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","        optimizer.step()\n","        total_loss += loss.item() * labels.size(0)\n","\n","    avg_loss = total_loss / len(train_loader.dataset)\n","    val_logits, y_val = infer_loader(model, val_loader)\n","    val_probs = 1 / (1 + np.exp(-val_logits))\n","    t_val, stats_val = find_best_threshold_probs(y_val, val_probs)\n","\n","    print(f\"Epoch {epoch} | Loss: {avg_loss:.4f} | Val Micro-F1: {stats_val['micro_f1']:.4f} | Threshold: {t_val:.2f}\")\n","\n","    if stats_val[\"micro_f1\"] > best_val_micro_f1:\n","        best_val_micro_f1 = stats_val[\"micro_f1\"]\n","        model.save_pretrained(CKPT_DIR)\n","        tokenizer.save_pretrained(CKPT_DIR)\n","        with open(os.path.join(CKPT_DIR, \"threshold.json\"), \"w\") as f:\n","            json.dump({\"best_threshold\": float(t_val), \"val_stats\": stats_val}, f, indent=2)\n","        no_improve = 0\n","    else:\n","        no_improve += 1\n","        if no_improve >= patience:\n","            print(\"Early stopping.\")\n","            break"],"metadata":{"id":"j9-T-PrtesFW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1755094166386,"user_tz":240,"elapsed":628768,"user":{"displayName":"3012 DEVADARSHINI P.T","userId":"12107410435582174408"}},"outputId":"c8e038d3-05a2-4d9b-d6d3-9d9b9568edb9"},"execution_count":44,"outputs":[{"output_type":"stream","name":"stdout","text":["Training :\n","Epoch 1 | Loss: 0.0970 | Val Micro-F1: 0.6499 | Threshold: 0.45\n","Epoch 2 | Loss: 0.0761 | Val Micro-F1: 0.6611 | Threshold: 0.45\n","Epoch 3 | Loss: 0.0738 | Val Micro-F1: 0.6731 | Threshold: 0.40\n","Epoch 4 | Loss: 0.0715 | Val Micro-F1: 0.6759 | Threshold: 0.45\n","Epoch 5 | Loss: 0.0676 | Val Micro-F1: 0.6762 | Threshold: 0.45\n","Epoch 6 | Loss: 0.0635 | Val Micro-F1: 0.7099 | Threshold: 0.45\n","Epoch 7 | Loss: 0.0579 | Val Micro-F1: 0.7102 | Threshold: 0.45\n","Epoch 8 | Loss: 0.0525 | Val Micro-F1: 0.7118 | Threshold: 0.45\n","Epoch 9 | Loss: 0.0488 | Val Micro-F1: 0.7325 | Threshold: 0.45\n","Epoch 10 | Loss: 0.0450 | Val Micro-F1: 0.7346 | Threshold: 0.45\n"]}]},{"cell_type":"markdown","source":["## Evaluation"],"metadata":{"id":"E9oybmr6sGXz"}},{"cell_type":"code","source":["from transformers import AutoModelForSequenceClassification\n","\n","with open(os.path.join(CKPT_DIR, \"threshold.json\"), \"r\") as f:\n","    meta_lb = json.load(f)\n","\n","best_t_lb = float(meta_lb[\"best_threshold\"])\n","best_val_stats_lb = {k: float(v) for k, v in meta_lb[\"val_stats\"].items()}\n","\n","legalbert_best = AutoModelForSequenceClassification.from_pretrained(CKPT_DIR).to(device)\n","legalbert_best.eval()\n","\n","test_logits_lb, y_test = infer_loader(legalbert_best, test_loader)\n","test_probs_lb = 1.0 / (1.0 + np.exp(-test_logits_lb))\n","y_test_hat_legalbert = (test_probs_lb >= best_t_lb).astype(int)\n","\n","test_stats_lb = multilabel_metrics(y_test, y_test_hat_legalbert)\n","\n","print(\"LegalBERT F1 Score (Micro):\", f1_score(y_test, y_test_hat_legalbert, average=\"micro\", zero_division=0))\n","print(\"VAL :\", {k: round(v, 4) for k, v in best_val_stats_lb.items()})\n","print(\"TEST:\", {k: round(v, 4) for k, v in test_stats_lb.items()})"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"45XL_FVwev0f","executionInfo":{"status":"ok","timestamp":1755094379527,"user_tz":240,"elapsed":14383,"user":{"displayName":"3012 DEVADARSHINI P.T","userId":"12107410435582174408"}},"outputId":"3f1dd431-746f-47bd-e4f4-3d97226462d1"},"execution_count":45,"outputs":[{"output_type":"stream","name":"stdout","text":["LegalBERT F1 Score (Micro): 0.7007654836464857\n","VAL : {'micro_f1': 0.7346, 'macro_f1': 0.443, 'micro_precision': 0.7019, 'micro_recall': 0.7704, 'macro_precision': 0.4456, 'macro_recall': 0.4712}\n","TEST: {'micro_f1': 0.7008, 'macro_f1': 0.4648, 'micro_precision': 0.6518, 'micro_recall': 0.7577, 'macro_precision': 0.552, 'macro_recall': 0.4956}\n"]}]},{"cell_type":"markdown","source":["## Sample Output"],"metadata":{"id":"Ma-Tbn666emQ"}},{"cell_type":"code","source":["def align_cols(A, N):\n","    A = np.asarray(A)\n","    if A.ndim == 1:\n","        A = A[None, :]\n","    if A.shape[1] > N:\n","        return A[:, :N]\n","    if A.shape[1] < N:\n","        pad = np.zeros((A.shape[0], N - A.shape[1]), dtype=A.dtype)\n","        return np.hstack([A, pad])\n","    return A\n","def names_from_vec(vec, names):\n","    vec = np.asarray(vec).ravel()\n","    N = min(len(vec), len(names))\n","    return [names[i] for i in range(N) if int(vec[i]) == 1]\n","\n","N = len(label_names)\n","y_test_arr = align_cols(y_test, N).astype(int)\n","y_pred_legalbert = align_cols(y_test_hat, N).astype(int)\n","\n","np.random.seed(42)\n","k = 3\n","idxs = np.random.choice(len(test_df), size=min(k, len(test_df)), replace=False)\n","\n","for idx in idxs:\n","    clause = test_df[\"clause_text\"].iloc[idx]\n","    clause_short = (clause[:600] + \"...\") if len(clause) > 600 else clause\n","\n","    true_labels = names_from_vec(y_test_arr[idx], label_names)\n","    pred_labels = names_from_vec(y_pred_legalbert[idx], label_names)\n","\n","    print(\"\\n— Clause —\")\n","    print(clause_short, \"\\n\")\n","    print(\" True:\", true_labels)\n","    print(\" Pred (LegalBERT):\", pred_labels)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q8Ixy3Ld6gl3","executionInfo":{"status":"ok","timestamp":1755096845456,"user_tz":240,"elapsed":10,"user":{"displayName":"3012 DEVADARSHINI P.T","userId":"12107410435582174408"}},"outputId":"885093d3-c478-4d3d-dd35-ce5f327d50bd"},"execution_count":56,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","— Clause —\n","Exhibit 10.5 STRATEGIC ALLIANCE AGREEMENT ---------------------------- THIS STRATEGIC ALLIANCE AGREEMENT (this \"Agreement\") is made as of 31 December, --------- 1996, between NORTHERN TELECOM LIMITED, a Canadian corporation (\"NTL\"), and --- ENTRUST TECHNOLOGIES INC., a Maryland corporation (\"ETI\"). --- WHEREAS, pursuant to an asset transfer agreement between NTL and Entrust Technologies Limited of even date (the \"NTL Transfer Agreement\") and an asset ---------------------- transfer agreement between Northern Telecom Inc. and ETI of even date, the Entrust Technology (as defined herein) has been... \n","\n"," True: ['Affiliate License-Licensee', 'Affiliate License-Licensor', 'Agreement Date', 'Anti-Assignment', 'Cap On Liability', 'Covenant Not To Sue', 'Governing Law', 'Irrevocable Or Perpetual License', 'Joint Ip Ownership', 'Minimum Commitment', 'No-Solicit Of Customers', 'Non-Disparagement', 'Price Restrictions', 'Revenue/Profit Sharing']\n"," Pred (LegalBERT): ['Agreement Date', 'Cap On Liability', 'Covenant Not To Sue', 'Governing Law', 'Insurance', 'Joint Ip Ownership', 'Revenue/Profit Sharing', 'Termination For Convenience', 'Volume Restriction']\n","\n","— Clause —\n","CONFIDENTIAL PORTIONS OMITTED EXHIBIT 10.16 [LOGO OF TEAM SABCO APPEARS HERE] SPONSORSHIP AGREEMENT THIS SPONSORSHIP AGREEMENT (hereinafter the \"Agreement) is made and entered into this 19th day of December 1997, by and between SABCO RACING, INC., a North Carolina corporation with a place of business in Iredell County, North Carolina (hereinafter Sabco), and Prolong Super Lubricants, Anaheim, Calif. (Hereinafter to be referred to as \"Prolong\"); WITNESSETH: WHEREAS, Sabco is engaged in the business of operating NASCAR Winston Cup Series race cars and wishes to provide advertising space and adve... \n","\n"," True: ['Agreement Date', 'Anti-Assignment', 'Governing Law', 'Ip Ownership Assignment', 'Irrevocable Or Perpetual License', 'Joint Ip Ownership', 'License Grant', 'Revenue/Profit Sharing']\n"," Pred (LegalBERT): ['Agreement Date', 'Governing Law', 'Insurance', 'Irrevocable Or Perpetual License', 'License Grant', 'Post-Termination Services', 'Revenue/Profit Sharing', 'Volume Restriction']\n","\n","— Clause —\n","925 West Georgia Street Suite 1820 Vancouver, British Columbia Canada V6C 3L2 Facsimile: 604-632-1730 PROMOTION AGREEMENT (the \"Agreement\") This agreement (the \"Agreement\") is made between Charity Tunes Inc., a British Columbia corporation with registered office located at Suite 1800, 925 West Georgia Street, Vancouver, British Columbia, Canada V6C 3L2 (\"Charity Tunes\") and ConAgra Foods Canada Inc. (\"Sponsor\") a Canada corporation, 5935 Airport Rd, Suite 405, Mississauga, Ontario, Canada L4V 1W5. WHEREAS as a new initiative, Charity Tunes and Sponsor will enter into a promotional partnership,... \n","\n"," True: ['Agreement Date', 'Anti-Assignment', 'Governing Law', 'Ip Ownership Assignment', 'Joint Ip Ownership', 'Revenue/Profit Sharing']\n"," Pred (LegalBERT): ['Agreement Date', 'Anti-Assignment', 'Audit Rights', 'Cap On Liability', 'Competitive Restriction Exception', 'Covenant Not To Sue', 'Governing Law', 'Insurance', 'Ip Ownership Assignment', 'Irrevocable Or Perpetual License', 'Joint Ip Ownership', 'License Grant', 'No-Solicit Of Customers', 'Non-Compete', 'Non-Disparagement', 'Post-Termination Services', 'Price Restrictions', 'Renewal Term', 'Revenue/Profit Sharing', 'Source Code Escrow', 'Termination For Convenience', 'Third Party Beneficiary', 'Uncapped Liability']\n"]}]},{"cell_type":"code","source":["import os, json, numpy as np, pandas as pd, torch\n","from torch.utils.data import Dataset, DataLoader\n","from transformers import AutoTokenizer, AutoModelForSequenceClassification\n","from sklearn.metrics import f1_score, precision_score, recall_score\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","class ClauseDatasetSimple(Dataset):\n","    def __init__(self, texts, labels, tokenizer, max_len=512, num_labels=None):\n","        self.texts = list(texts)\n","        arr = np.array(list(labels), dtype=np.float32)\n","        if num_labels is not None:\n","            if arr.ndim == 1:\n","                arr = arr[None, :]\n","            if arr.shape[1] > num_labels:\n","                arr = arr[:, :num_labels]\n","            elif arr.shape[1] < num_labels:\n","                pad = np.zeros((arr.shape[0], num_labels - arr.shape[1]), dtype=np.float32)\n","                arr = np.hstack([arr, pad])\n","        self.labels = arr\n","        self.tokenizer = tokenizer\n","        self.max_len = max_len\n","\n","    def __len__(self): return len(self.texts)\n","\n","    def __getitem__(self, idx):\n","        enc = self.tokenizer(\n","            self.texts[idx], truncation=True, padding=\"max_length\",\n","            max_length=self.max_len, return_tensors=\"pt\"\n","        )\n","        item = {k: v.squeeze(0) for k, v in enc.items()}\n","        item[\"labels\"] = torch.tensor(self.labels[idx], dtype=torch.float32)\n","        return item\n","\n","def infer_loader(model, loader):\n","    model.eval()\n","    all_logits, all_labels = [], []\n","    with torch.no_grad():\n","        for batch in loader:\n","            inputs = {k: v.to(device) for k, v in batch.items() if k != \"labels\"}\n","            labels = batch[\"labels\"].to(device)\n","            logits = model(**inputs).logits\n","            all_logits.append(logits.detach().cpu().numpy())\n","            all_labels.append(labels.detach().cpu().numpy())\n","    return np.vstack(all_logits), np.vstack(all_labels)\n","\n","def evaluate_ckpt(ckpt_dir, model_name, max_len=512, batch_size=8):\n","    \"\"\"Load tokenizer+model from ckpt_dir, rebuild test loader, evaluate with saved threshold.\"\"\"\n","    thresh_path = os.path.join(ckpt_dir, \"threshold.json\")\n","    if not (os.path.isdir(ckpt_dir) and os.path.isfile(thresh_path)):\n","        return None, f\"[skip] Missing checkpoint or threshold.json for {model_name} at {ckpt_dir}\"\n","    tok = AutoTokenizer.from_pretrained(ckpt_dir, use_fast=True)\n","    mdl = AutoModelForSequenceClassification.from_pretrained(ckpt_dir).to(device)\n","\n","    num_labels = mdl.config.num_labels\n","    test_ds = ClauseDatasetSimple(\n","        test_df[\"clause_text\"], test_df[\"y_multi\"],\n","        tokenizer=tok, max_len=max_len, num_labels=num_labels\n","    )\n","    test_loader = DataLoader(test_ds, batch_size=batch_size)\n","\n","    with open(thresh_path, \"r\") as f:\n","        meta = json.load(f)\n","    best_t = float(meta.get(\"best_threshold\", 0.5))\n","    val_stats = {k: float(v) for k, v in meta.get(\"val_stats\", {}).items()}\n","\n","\n","    test_logits, y_test = infer_loader(mdl, test_loader)\n","    test_probs = 1.0 / (1.0 + np.exp(-test_logits))\n","    y_hat = (test_probs >= best_t).astype(int)\n","    test_stats = multilabel_metrics(y_test, y_hat)\n","\n","    row = {\n","        \"model\": model_name,\n","        \"n_labels\": int(num_labels),\n","        \"best_t\": round(best_t, 3),\n","        \"val_micro_f1\": round(val_stats.get(\"micro_f1\", float(\"nan\")), 4),\n","        \"val_macro_f1\": round(val_stats.get(\"macro_f1\", float(\"nan\")), 4),\n","        \"test_micro_f1\": round(test_stats[\"micro_f1\"], 4),\n","        \"test_macro_f1\": round(test_stats[\"macro_f1\"], 4),\n","        \"test_precision\": round(test_stats[\"micro_precision\"], 4),\n","        \"test_recall\": round(test_stats[\"micro_recall\"], 4),\n","    }\n","    return row, None\n","\n","CKPTS = [\n","    (\"RoBERTa\",   \"/content/drive/MyDrive/data_cuad_transformer/ckpt_roberta_finetuned\"),\n","    (\"LegalBERT\", \"/content/drive/MyDrive/data_cuad_transformer/ckpt_legalbert_finetuned\"),\n","     (\"BERT\",      \"/content/drive/MyDrive/data_cuad_transformer/ckpt_bert_finetuned\"),\n","]\n","\n","rows, notes = [], []\n","for name, path in CKPTS:\n","    r, msg = evaluate_ckpt(path, name, max_len=512, batch_size=8)\n","    if r is not None:\n","        rows.append(r)\n","    if msg:\n","        notes.append(msg)\n","\n","if rows:\n","    results_df = (pd.DataFrame(rows)\n","                    .sort_values(\"test_micro_f1\", ascending=False)\n","                    .reset_index(drop=True))\n","    display(results_df)\n","    print(f\"\\nBest: {results_df.iloc[0]['model']} | test micro-F1={results_df.iloc[0]['test_micro_f1']:.4f} | n_labels={results_df.iloc[0]['n_labels']} | best_t={results_df.iloc[0]['best_t']:.3f}\")\n","else:\n","    print(\"No models evaluated. Check CKPT paths/threshold.json files.\")\n","\n","for n in notes:\n","    print(n)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":176},"id":"mZSuwCyN61Re","executionInfo":{"status":"ok","timestamp":1755097146807,"user_tz":240,"elapsed":32489,"user":{"displayName":"3012 DEVADARSHINI P.T","userId":"12107410435582174408"}},"outputId":"f4d7d2c3-dc7a-48d3-b578-032e2c05af82"},"execution_count":57,"outputs":[{"output_type":"display_data","data":{"text/plain":["       model  n_labels  best_t  val_micro_f1  val_macro_f1  test_micro_f1  \\\n","0    RoBERTa        39    0.40        0.7376        0.4636         0.5202   \n","1  LegalBERT        41    0.45        0.7346        0.4430         0.5201   \n","2       BERT        41    0.40        0.6256        0.4957         0.5001   \n","\n","   test_macro_f1  test_precision  test_recall  \n","0         0.3295          0.4400       0.6362  \n","1         0.3184          0.4608       0.5968  \n","2         0.3942          0.3794       0.7334  "],"text/html":["\n","  <div id=\"df-7bc95ff2-f780-48fc-8d6f-a44868e241cc\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>model</th>\n","      <th>n_labels</th>\n","      <th>best_t</th>\n","      <th>val_micro_f1</th>\n","      <th>val_macro_f1</th>\n","      <th>test_micro_f1</th>\n","      <th>test_macro_f1</th>\n","      <th>test_precision</th>\n","      <th>test_recall</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>RoBERTa</td>\n","      <td>39</td>\n","      <td>0.40</td>\n","      <td>0.7376</td>\n","      <td>0.4636</td>\n","      <td>0.5202</td>\n","      <td>0.3295</td>\n","      <td>0.4400</td>\n","      <td>0.6362</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>LegalBERT</td>\n","      <td>41</td>\n","      <td>0.45</td>\n","      <td>0.7346</td>\n","      <td>0.4430</td>\n","      <td>0.5201</td>\n","      <td>0.3184</td>\n","      <td>0.4608</td>\n","      <td>0.5968</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>BERT</td>\n","      <td>41</td>\n","      <td>0.40</td>\n","      <td>0.6256</td>\n","      <td>0.4957</td>\n","      <td>0.5001</td>\n","      <td>0.3942</td>\n","      <td>0.3794</td>\n","      <td>0.7334</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7bc95ff2-f780-48fc-8d6f-a44868e241cc')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-7bc95ff2-f780-48fc-8d6f-a44868e241cc button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-7bc95ff2-f780-48fc-8d6f-a44868e241cc');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-6b65ca24-c7be-4413-9dd7-c67fb4e95891\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6b65ca24-c7be-4413-9dd7-c67fb4e95891')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-6b65ca24-c7be-4413-9dd7-c67fb4e95891 button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","  <div id=\"id_b3ca950f-49b7-41f8-9508-38747a520d3c\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('results_df')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_b3ca950f-49b7-41f8-9508-38747a520d3c button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('results_df');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"results_df","summary":"{\n  \"name\": \"results_df\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"model\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"RoBERTa\",\n          \"LegalBERT\",\n          \"BERT\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"n_labels\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 39,\n        \"max\": 41,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          41,\n          39\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"best_t\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.02886751345948128,\n        \"min\": 0.4,\n        \"max\": 0.45,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.45,\n          0.4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"val_micro_f1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.06381483631047981,\n        \"min\": 0.6256,\n        \"max\": 0.7376,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.7376,\n          0.7346\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"val_macro_f1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.026558300648447605,\n        \"min\": 0.443,\n        \"max\": 0.4957,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.4636,\n          0.443\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"test_micro_f1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.011575980879965787,\n        \"min\": 0.5001,\n        \"max\": 0.5202,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.5202,\n          0.5201\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"test_macro_f1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.040936821241192294,\n        \"min\": 0.3184,\n        \"max\": 0.3942,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.3295,\n          0.3184\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"test_precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0422905820878991,\n        \"min\": 0.3794,\n        \"max\": 0.4608,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.44,\n          0.4608\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"test_recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.07030855803764814,\n        \"min\": 0.5968,\n        \"max\": 0.7334,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.6362,\n          0.5968\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","Best: RoBERTa | test micro-F1=0.5202 | n_labels=39 | best_t=0.400\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"mXHkiKu28KXy"},"execution_count":null,"outputs":[]}]}